version: '3.9'

services:
  postgres:
    image: postgres:14
    container_name: fire_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pg_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  etl:
    build: .
    container_name: fire_etl
    environment:
      - API_URL=${API_URL}
      - API_KEY=${API_KEY}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    depends_on:
      - postgres

  dbt:
    image: fishtownanalytics/dbt:1.0.0
    container_name: fire_dbt
    volumes:
      - ./dbt:/usr/app
    working_dir: /usr/app
    environment:
      DBT_PROFILES_DIR: /usr/app
    command: dbt run

  airflow:
    image: apache/airflow:2.7.0-python3.10
    container_name: fire_airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    command: bash -c "airflow db init && airflow users create --username admin --password admin --firstname Air --lastname Flow --role Admin --email admin@example.com && airflow webserver"

volumes:
  pg_data:

